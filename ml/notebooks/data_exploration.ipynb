{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "We import the core Python libraries required for data manipulation, path handling, and exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ml.src.config.paths import (\n",
    "    RAW_TRAIN_PATH,\n",
    "    RAW_TEST_PATH,\n",
    "    CLEANED_TRAIN_PATH,\n",
    "    CLEANED_TEST_PATH,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Loading the Training and Test Datasets\n",
    "\n",
    "The training and test datasets are loaded from the `data/` directory. Paths are resolved explicitly to avoid issues with relative locations.\n",
    "These datasets will be used for exploratory data analysis and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(RAW_TRAIN_PATH)\n",
    "test_data = pd.read_csv(RAW_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Combine Training and Test Data for Consistent Preprocessing\n",
    "\n",
    "To ensure consistent feature engineering and preprocessing, we temporarily combine the training and test datasets.\n",
    "A flag (`is_train`) is added to allow safe separation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['is_train'] = 1\n",
    "test_data['is_train'] = 0\n",
    "\n",
    "full_data = pd.concat([train_data, test_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Previewing the Training Data\n",
    "\n",
    "A quick preview helps verify that the data has loaded correctly and provides an initial sense of feature types and values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Inspecting Dataset Structure and Data Types\n",
    "\n",
    "The info() method provides a concise summary of the dataset, including:\n",
    "\n",
    "1. Number of entries\n",
    "\n",
    "2. Column names\n",
    "\n",
    "3. Data types\n",
    "\n",
    "4. Count of non-null values\n",
    "\n",
    "This is especially useful for identifying missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Statistical Summary of Numerical Features\n",
    "\n",
    "The describe() method generates descriptive statistics for numerical columns, such as:\n",
    "\n",
    "1. Mean\n",
    "\n",
    "2. Standard deviation\n",
    "\n",
    "3. Minimum and maximum values\n",
    "\n",
    "4. Quartiles\n",
    "\n",
    "This gives an overview of data distribution and potential anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Identifying Missing Age Values\n",
    "\n",
    "Here we filter the dataset to show only rows where the Age column has missing values (NaN).\n",
    "This helps us understand how many records are affected and plan an imputation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data['Age'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Extract Passenger Titles from Names\n",
    "\n",
    "Passenger titles (e.g., Mr, Mrs, Miss) are extracted from the Name column using a regular expression.\n",
    "Titles often capture social status and correlate strongly with age and survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Title'] = full_data['Name'].str.extract(r',\\s*([^\\.]+)\\.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Grouping Rare Titles\n",
    "\n",
    "Many titles appear very infrequently.\n",
    "To reduce noise and dimensionality, we group uncommon titles into a single category called \"Rare\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Title'] = full_data['Title'].where(\n",
    "full_data['Title'].isin(['Mr', 'Mrs', 'Master', 'Miss']),\n",
    "'Rare'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Encoding Titles as Numerical Values\n",
    "\n",
    "Machine learning models require numerical inputs.\n",
    "Here we map each title category to an integer value for model compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {\n",
    "    'Mr': 0,\n",
    "    'Miss': 1,\n",
    "    'Mrs': 2,\n",
    "    'Master': 3,\n",
    "    'Rare': 4\n",
    "}\n",
    "\n",
    "full_data['Title'] = full_data['Title'].map(title_mapping)\n",
    "\n",
    "\n",
    "full_data['Title'] = full_data['Title'].fillna(4)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Impute Missing Age Values Using Training Data Only\n",
    "\n",
    "Missing values in the Age column are filled using the average age per title, calculated only from the training data.\n",
    "This avoids data leakage while producing more realistic age estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_age_means = (\n",
    "    full_data[full_data['is_train'] == 1]\n",
    "    .groupby('Title')['Age']\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "for title, avg_age in title_age_means.items():\n",
    "    full_data.loc[\n",
    "        (full_data['Title'] == title) & (full_data['Age'].isna()),\n",
    "        'Age'\n",
    "    ] = round(avg_age, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Validating the Sex Column\n",
    "\n",
    "We check whether the Sex column contains only the expected values (male, female).\n",
    "This ensures data consistency before encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[~train_data['Sex'].isin(['male', 'female'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Encoding Sex as Numerical Values\n",
    "\n",
    "We convert the categorical Sex column into numeric form:\n",
    "\n",
    "male → 0\n",
    "\n",
    "female → 1\n",
    "\n",
    "This is required for machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Sex'] = full_data['Sex'].map({\n",
    "    'male': 0,\n",
    "    'female': 1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Exploring the Embarked Feature\n",
    "\n",
    "We inspect the Embarked column, which represents the port where passengers boarded the ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Embarked']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Validating Embarked Values\n",
    "\n",
    "This step checks for unexpected or invalid embarkation values outside the known categories:\n",
    "\n",
    "S (Southampton)\n",
    "\n",
    "C (Cherbourg)\n",
    "\n",
    "Q (Queenstown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[~train_data['Embarked'].isin(['S','C','Q'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Handling Missing Embarked Values\n",
    "\n",
    "Missing values in Embarked are filled with 'C', which is the most frequent embarkation port in this dataset.\n",
    "This ensures no missing values remain in this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Embarked'] = full_data['Embarked'].fillna('C')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Split the Combined Dataset Back into Train and Test\n",
    "\n",
    "After preprocessing, we separate the combined dataset back into cleaned training and test datasets.\n",
    "The helper column is_train is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = full_data[full_data['is_train'] == 1].drop(columns=['is_train'])\n",
    "test_cleaned = full_data[full_data['is_train'] == 0].drop(columns=['is_train'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Remove Survived from test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cleaned = test_cleaned.drop(columns=['Survived'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Handling Missing Fare Values in Test Set\n",
    "\n",
    "Missing fare values in the test dataset are imputed using\n",
    "the median fare from the training dataset to prevent data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_median = train_cleaned['Fare'].median()\n",
    "test_cleaned['Fare'] = test_cleaned['Fare'].fillna(fare_median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Final Data Validation\n",
    "\n",
    "As a final check, we confirm that there are no unexpected missing values remaining in either dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train missing values:\")\n",
    "print(train_cleaned.isna().sum())\n",
    "\n",
    "print(\"\\nTest missing values:\")\n",
    "print(test_cleaned.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Export Cleaned Datasets to CSV Files\n",
    "\n",
    "The cleaned datasets are saved as CSV files for use in modeling and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANED_TRAIN_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_cleaned.to_csv(CLEANED_TRAIN_PATH, index=False)\n",
    "test_cleaned.to_csv(CLEANED_TEST_PATH, index=False)\n",
    "\n",
    "print(f\"Saved train_cleaned.csv to: {CLEANED_TRAIN_PATH}\")\n",
    "print(f\"Saved test_cleaned.csv to: {CLEANED_TEST_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic-capstone-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
